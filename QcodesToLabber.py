from qcodes.dataset.sqlite.database import connect
from qcodes.dataset.data_set import get_guids_by_run_spec,load_by_guid
from qcodes.dataset.data_set_protocol import DataSetProtocol
import h5py
import os
import time
import Labber

def QCoDeSDBtoLabber(DBpath: str, dumpPath: str) -> None:
    """Generate HDF5 files from QCoDeS database.
    All runs in all experiments will be converted to HDF5 files that the
    Labber Log Browser can read.
    The full folder structure expected by the Log Browser will be created
    by the QCoDesToLabber function.

    BDPath: path to the QCoDes database.
    dumpPath: Top level folder where the generated files should be stored.
    """
    # Connect the SQLite database
    db_conn = connect(DBpath)

    # Iterate over all runs
    for i,guid in enumerate(get_guids_by_run_spec(conn=db_conn)):
        dataset = load_by_guid(guid=guid,conn=db_conn)

        # Create Labber HDF5 file
        QCoDeSToLabber(dataset,dumpPath)

def QCoDeSToLabber(dataset: DataSetProtocol, dumpPath: str) -> None:
    """Generate a HDF5 file from a QCodes dataset.
    Single HDF5 file will be created within a folder structure expected
    by the Labber Log Browser.

    dataset: QCoDes dataset generated by QCoDes from a single run.
    dumpPath: Top level folder where the generated file should be stored.
    """
    # Create folder structure expected by the Labber Log Browser
    ts = time.strptime(dataset.run_timestamp(),"%Y-%m-%d %H:%M:%S")
    LabberPath = '{}\\{:02d}\\Data_{:02d}{:02d}'.format(ts.tm_year,ts.tm_mon,ts.tm_mon,ts.tm_mday)
    folderPath = os.path.join(dumpPath,LabberPath)

    # Check if folder structure exist and create it if not
    folderExist = os.path.exists(folderPath)
    if not folderExist:
        os.makedirs(folderPath)

    # Generate a unique file name and remove any charaters that will break the path
    fileName = f"{dataset.name}_{dataset.exp_name}_{dataset.sample_name}_{dataset.captured_run_id}".replace(" ", "_")
    fileName = fileName.translate({ord(ch):'' for ch in '\/,.'})
    filePath = os.path.join(folderPath,fileName)

    xdata = dataset.to_xarray_dataset()

    # Generate dicts with metadata from the independent parameters
    lStep = [
        dict(name=dim, unit=xdata[dim].attrs["unit"], values=xdata[dim].values)
        for dim in reversed(list(xdata.dims))
    ]

    # Generate dicts with metadata from the dependent parameters
    lLog = [
        dict(name=var, unit=xdata[var].attrs["unit"], vector=False)
        for var in xdata.data_vars
    ]

    # Create HDF5 container
    f = Labber.createLogFile_ForData(filePath, lLog, lStep, use_database=False)

    # Add the measured data
    try:
        if len(lStep) == 1:
            data = {vardim: xdata[vardim] for vardim in xdata.data_vars}
            f.addEntry(data)
        else:
            for i in range(len(lStep[1]["values"])):
                data = {vardim: xdata[vardim][i] for vardim in xdata.data_vars}
                f.addEntry(data)
    except:
        print('Error while generating {}. The HDF5 file might be incomplete!'.format(fileName))

    # Add comment if present
    try:
        comment = xdata.attrs['Comment']
        f.setComment(comment)
    except:
        # do nothing
        pass
